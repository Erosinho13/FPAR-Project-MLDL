{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23325,
     "status": "ok",
     "timestamp": 1591213528318,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "cPAQpsvWynjD",
    "outputId": "b473fabe-b422-4fc9-913c-fa1a362d3a1b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11106,
     "status": "ok",
     "timestamp": 1591213582575,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "dfiRjXH3yQ6A",
    "outputId": "f06b3b09-8082-4ca9-da64-affa98cd4b86"
   },
   "outputs": [],
   "source": [
    "%cd drive/My\\ Drive/\n",
    "!git clone https://[username]:[password]@github.com/Erosinho13/FPAR-Project-MLDL.git\n",
    "%cd FPAR-Project-MLDL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2lsdTrTBZrA"
   },
   "source": [
    "# SETUP\n",
    "The following blocks are to be executed first of anything else, to setup import, classes, functions and \n",
    "constants that are needed for all stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9G569ps3BdBw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from logs import Logger, generate_model_checkpoint_name, generate_log_filenames\n",
    "\n",
    "from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n",
    "from AttentionModelMS import attention_model_ms\n",
    "from flow_resnet import flow_resnet34\n",
    "from twoStreamModel import twoStreamAttentionModel\n",
    "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
    "                                RandomHorizontalFlip, DownSampling, To1Dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IX0KVsVBjwh"
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "NUM_CLASSES = 61 # 101 + 1: There is am extra Background class that should be removed \n",
    "\n",
    "BATCH_SIZE = 32     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "MMAP_LENGTH = 49\n",
    "DATA_DIR = '../GTEA61'\n",
    "model_folder = '../saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjo-WeDUCKtm"
   },
   "outputs": [],
   "source": [
    "# Data loader\n",
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "default_transforms = [\n",
    "    Scale(256),\n",
    "    RandomHorizontalFlip(),\n",
    "    MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
    "    ToTensor()\n",
    "]\n",
    "\n",
    "spatial_transform = Compose(default_transforms + [normalize])\n",
    "spatial_transform_mmaps = Compose(default_transforms + [DownSampling(), To1Dimension()])\n",
    "spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9wsXdedDE90"
   },
   "source": [
    "# Stage 1 specific-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dO0j_wjwDARB"
   },
   "outputs": [],
   "source": [
    "STAGE = 1\n",
    "\n",
    "LR = 0.001                            # The initial Learning Rate\n",
    "MOMENTUM = 0.9                        # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 4e-5                   # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 200                      # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = [25, 75, 150]             # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1                           # Multiplicative factor for learning rate step-down\n",
    "MEM_SIZE = 512\n",
    "SEQ_LEN = 7\n",
    "\n",
    "# this dictionary is needed for the logger class\n",
    "parameters = {\n",
    "    'DEVICE': DEVICE,\n",
    "    'NUM_CLASSES': NUM_CLASSES,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'LR': LR,\n",
    "    'MOMENTUM': MOMENTUM,\n",
    "    'WEIGHT_DECAY': WEIGHT_DECAY,\n",
    "    'NUM_EPOCHS': NUM_EPOCHS,\n",
    "    'STEP_SIZE': STEP_SIZE,\n",
    "    'GAMMA': GAMMA,\n",
    "    'MEM_SIZE': MEM_SIZE,\n",
    "    'SEQ_LEN': SEQ_LEN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1591096194672,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "Wfttpj_7DikR",
    "outputId": "37a6e011-45db-46c3-c2da-2db9196e141a"
   },
   "outputs": [],
   "source": [
    "# Prepare Pytorch train/test Datasets\n",
    "train_dataset = GTEA61(DATA_DIR, split = 'train', transform = spatial_transform, seq_len = SEQ_LEN,\n",
    "                       mmaps = True, mmaps_transform = spatial_transform_mmaps)\n",
    "test_dataset = GTEA61(DATA_DIR, split = 'test', transform = spatial_transform_val, seq_len = SEQ_LEN)\n",
    "\n",
    "# Check dataset sizes\n",
    "print('Train Dataset: {}'.format(len(train_dataset)))\n",
    "print('Test Dataset: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4PJpn_zD97F"
   },
   "outputs": [],
   "source": [
    "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, drop_last = True)\n",
    "val_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oToJxBGEH1U"
   },
   "source": [
    "# Prepare stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ud6mw-NYED3C"
   },
   "outputs": [],
   "source": [
    "validate = True\n",
    "\n",
    "model = attention_model_ms(num_classes = NUM_CLASSES, mem_size = MEM_SIZE)\n",
    "model.train(False)\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "for params in model.lstm_cell.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "for params in model.classifier.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "model.lstm_cell.train(True)\n",
    "model.classifier.train(True)\n",
    "model.to(DEVICE)\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_fn = optim.Adam(trainable_params, lr = LR, weight_decay = WEIGHT_DECAY, eps = 1e-4)\n",
    "\n",
    "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones = STEP_SIZE, gamma = GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "laVQMCiNFVb2"
   },
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7292417,
     "status": "ok",
     "timestamp": 1591103561784,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "nWwgaMAMFQXs",
    "outputId": "dc3e2d19-a5d8-4a08-9e7a-75b73618818e"
   },
   "outputs": [],
   "source": [
    "train_iter = 0\n",
    "val_iter = 0\n",
    "min_accuracy = 0\n",
    "\n",
    "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
    "val_samples = len(test_dataset) \n",
    "iterPerEpoch = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "\n",
    "cudnn.benchmark\n",
    "\n",
    "train_log, val_log = generate_log_filenames(STAGE, SEQ_LEN, ms_block = True, \\\n",
    "                                            optional = 'ReLU_before_and_after')\n",
    "model_checkpoint = generate_model_checkpoint_name(STAGE, SEQ_LEN, ms_block = True, \\\n",
    "                                                  optional = 'ReLU_before_and_after')\n",
    "\n",
    "train_log_file = os.path.join(model_folder, train_log)\n",
    "val_log_file = os.path.join(model_folder, val_log)\n",
    "\n",
    "train_logger = Logger(**parameters)\n",
    "val_logger = Logger(**parameters)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    numCorrTrain = 0\n",
    "    \n",
    "    model.lstm_cell.train(True)\n",
    "    model.classifier.train(True)\n",
    "        \n",
    "    for i, (inputs, _, targets) in enumerate(train_loader):\n",
    "\n",
    "        train_iter += 1\n",
    "\n",
    "        optimizer_fn.zero_grad()\n",
    "\n",
    "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
    "        labelVariable = targets.to(DEVICE)\n",
    "        output_label, _ = model(inputVariable)\n",
    "        \n",
    "        loss = loss_fn(output_label, labelVariable)\n",
    "        loss.backward()\n",
    "        optimizer_fn.step()\n",
    "            \n",
    "        _, predicted = torch.max(output_label.data, 1)\n",
    "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
    "\n",
    "        step_loss = loss.data.item()\n",
    "        epoch_loss += step_loss\n",
    "\n",
    "        train_logger.add_step_data(train_iter, numCorrTrain, step_loss)\n",
    "    \n",
    "    avg_loss = epoch_loss/iterPerEpoch\n",
    "\n",
    "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
    "    train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
    "    print('Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
    "\n",
    "    if validate:\n",
    "\n",
    "        if (epoch+1) % 1 == 0:\n",
    "\n",
    "            model.train(False)\n",
    "\n",
    "            val_loss_epoch = 0\n",
    "            numCorr = 0\n",
    "\n",
    "            for j, (inputs, targets) in enumerate(val_loader):\n",
    "\n",
    "                val_iter += 1\n",
    "\n",
    "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
    "                labelVariable = targets.to(DEVICE)\n",
    "                \n",
    "                output_label, _ = model(inputVariable)\n",
    "\n",
    "                val_loss = loss_fn(output_label, labelVariable)\n",
    "                val_loss_step = val_loss.data.item()\n",
    "                val_loss_epoch += val_loss_step\n",
    "                \n",
    "                _, predicted = torch.max(output_label.data, 1)\n",
    "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
    "\n",
    "                val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
    "                \n",
    "            val_accuracy = (numCorr / val_samples) * 100\n",
    "            avg_val_loss = val_loss_epoch / val_steps\n",
    "            val_logger.add_epoch_data(epoch+1, val_accuracy, avg_val_loss)\n",
    "\n",
    "            print('Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
    "\n",
    "            if val_accuracy > min_accuracy:\n",
    "                print(\"[||| NEW BEST on val||||]\")\n",
    "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
    "                torch.save(model.state_dict(), save_path_model)\n",
    "                min_accuracy = val_accuracy\n",
    "        \n",
    "    train_logger.save(train_log_file)\n",
    "    val_logger.save(val_log_file)\n",
    "    optim_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjwHu7nlwPOO"
   },
   "source": [
    "# Stage 2 specific-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWvGKBdUwQUf"
   },
   "outputs": [],
   "source": [
    "STAGE = 2\n",
    "\n",
    "LR = 0.0001            # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 150      # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = [25, 75] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "MEM_SIZE = 512\n",
    "SEQ_LEN = 7\n",
    "\n",
    "parameters = {\n",
    "    'DEVICE': DEVICE,\n",
    "    'NUM_CLASSES': NUM_CLASSES,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'LR': LR,\n",
    "    'MOMENTUM': MOMENTUM,\n",
    "    'WEIGHT_DECAY': WEIGHT_DECAY,\n",
    "    'NUM_EPOCHS': NUM_EPOCHS,\n",
    "    'STEP_SIZE': STEP_SIZE,\n",
    "    'GAMMA': GAMMA,\n",
    "    'MEM_SIZE': MEM_SIZE,\n",
    "    'SEQ_LEN': SEQ_LEN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 533223,
     "status": "ok",
     "timestamp": 1591214138673,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "Y6LvKvL7_0ND",
    "outputId": "1225d1e1-c8c5-46be-a031-6b7dc43ef6c6"
   },
   "outputs": [],
   "source": [
    "# Prepare Pytorch train/test Datasets\n",
    "train_dataset = GTEA61(DATA_DIR, split='train', transform=spatial_transform,\n",
    "                       seq_len=SEQ_LEN, mmaps = True, mmaps_transform = spatial_transform_mmaps)\n",
    "test_dataset = GTEA61(DATA_DIR, split='test', transform=spatial_transform_val,\n",
    "                      seq_len=SEQ_LEN)\n",
    "\n",
    "# Check dataset sizes\n",
    "print('Train Dataset: {}'.format(len(train_dataset)))\n",
    "print('Test Dataset: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmnYcBVT_zHm"
   },
   "outputs": [],
   "source": [
    "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmCrfp8AABdl"
   },
   "source": [
    "# Prepare stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "9c057e399c704c43a03beb529d12ae2e",
      "b562fe7ff1b644ce8a68d6d9c39ae859",
      "953b1cb988ef4cd98e71dc38111c710f",
      "a08bc17b8b4543bf940995d154777641",
      "38ef672389194c63af556682bcdfa612",
      "48dc2d6bc04b4922bdfda5543c32551a",
      "43d821a2ad0e484484d13d924a435920",
      "056980d18ea54cb887e09ee2d1cf08ab"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15969,
     "status": "ok",
     "timestamp": 1591214156902,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "sXMbHelUwWv2",
    "outputId": "312abffc-c1dc-4b28-e093-c0e00420f2ff"
   },
   "outputs": [],
   "source": [
    "best_old_stage = generate_model_checkpoint_name(stage=1, n_frames=SEQ_LEN, ms_block = True)\n",
    "stage1_dict = os.path.join(model_folder, best_old_stage)\n",
    "validate = True\n",
    "\n",
    "model = attention_model_ms(num_classes=NUM_CLASSES, mem_size=MEM_SIZE)\n",
    "model.load_state_dict(torch.load(stage1_dict))\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "layers_to_train = [\n",
    "    model.resNet.layer4[0].conv1,\n",
    "    model.resNet.layer4[0].conv2,\n",
    "    model.resNet.layer4[1].conv1,\n",
    "    model.resNet.layer4[1].conv2,\n",
    "    model.resNet.layer4[2].conv1,\n",
    "    model.resNet.layer4[2].conv2,\n",
    "    model.resNet.fc,\n",
    "    model.lstm_cell,\n",
    "    model.classifier,\n",
    "    model.msBlock\n",
    "]\n",
    "\n",
    "for layer in layers_to_train:\n",
    "    for params in layer.parameters():\n",
    "        params.requires_grad = True\n",
    "\n",
    "for layer in layers_to_train:\n",
    "    layer.train(True)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn_sum = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer_fn = torch.optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
    "\n",
    "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmAez0fl_uCY"
   },
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46598,
     "status": "error",
     "timestamp": 1591106383063,
     "user": {
      "displayName": "Eros Fanì",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapRbf5lUkHjaoCtjruM95BBemedtJFkNrcJgVKA=s64",
      "userId": "05010694830681132177"
     },
     "user_tz": -120
    },
    "id": "oe-sovUP_u7M",
    "outputId": "ce695046-d92a-4773-873a-ab49c78a3a30"
   },
   "outputs": [],
   "source": [
    "train_iter = 0\n",
    "val_iter = 0\n",
    "min_accuracy = 0\n",
    "\n",
    "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
    "val_samples = len(test_dataset)\n",
    "\n",
    "iterPerEpoch = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "\n",
    "cudnn.benchmark\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "train_log, val_log = generate_log_filenames(STAGE, SEQ_LEN, ms_block = True)\n",
    "model_checkpoint = generate_model_checkpoint_name(STAGE, SEQ_LEN, ms_block = True)\n",
    "\n",
    "train_log_file = os.path.join(model_folder, train_log)\n",
    "val_log_file = os.path.join(model_folder, val_log)\n",
    "train_logger_2 = Logger(**parameters)\n",
    "val_logger_2 = Logger(**parameters)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    numCorrTrain = 0\n",
    "    \n",
    "    for layer in layers_to_train:\n",
    "        layer.train(True)\n",
    "    \n",
    "    for i, (inputs, mmaps, targets) in enumerate(train_loader):\n",
    "\n",
    "        mmaps = mmaps.permute(1, 0, 2)\n",
    "\n",
    "        train_iter += 1\n",
    "\n",
    "        optimizer_fn.zero_grad()\n",
    "\n",
    "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
    "        labelVariable = targets.to(DEVICE)\n",
    "\n",
    "        output_label, _, output_label_mmaps = model(inputVariable, mmaps = True)\n",
    "\n",
    "        output_label_mmaps = torch.flatten(output_label_mmaps).unsqueeze_(-1) + torch.zeros(2).to(DEVICE)\n",
    "        output_label_mmaps[:, 0] = 1 - output_label_mmaps[:, 1]\n",
    "        output_label_mmaps = output_label_mmaps.to(DEVICE)\n",
    "        \n",
    "        mmaps = torch.flatten(mmaps).long().to(DEVICE)\n",
    "\n",
    "        loss = loss_fn_sum(output_label_mmaps, mmaps)/(BATCH_SIZE * MMAP_LENGTH) + \\\n",
    "               loss_fn(output_label, labelVariable)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_fn.step()\n",
    "        \n",
    "        _, predicted = torch.max(output_label.data, 1)\n",
    "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
    "        step_loss = loss.data.item()\n",
    "        epoch_loss += step_loss\n",
    "        train_logger_2.add_step_data(train_iter, numCorrTrain, step_loss)\n",
    "\n",
    "        \n",
    "    avg_loss = epoch_loss/iterPerEpoch\n",
    "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
    "    train_logger_2.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
    "    \n",
    "    print('Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
    "\n",
    "    if validate is not None:\n",
    "\n",
    "        if (epoch+1) % 1 == 0:\n",
    "\n",
    "            model.train(False)\n",
    "            val_loss_epoch = 0\n",
    "            numCorr = 0\n",
    "\n",
    "            for j, (inputs, targets) in enumerate(val_loader):\n",
    "\n",
    "                val_iter += 1\n",
    "\n",
    "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
    "                labelVariable = targets.to(DEVICE)\n",
    "                \n",
    "                output_label, _ = model(inputVariable)\n",
    "\n",
    "                val_loss = loss_fn(output_label, labelVariable)\n",
    "                val_loss_step = val_loss.data.item()\n",
    "                val_loss_epoch += val_loss_step\n",
    "\n",
    "                _, predicted = torch.max(output_label.data, 1)\n",
    "\n",
    "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
    "                val_logger_2.add_step_data(val_iter, numCorr, val_loss_step)\n",
    "\n",
    "            val_accuracy = (numCorr / val_samples) * 100\n",
    "            avg_val_loss = val_loss_epoch / val_steps\n",
    "\n",
    "            print('Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
    "            \n",
    "            val_logger_2.add_epoch_data(epoch+1, val_accuracy, avg_val_loss)\n",
    "            \n",
    "            if val_accuracy > min_accuracy:\n",
    "                print(\"[||| NEW BEST on val |||]\")\n",
    "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
    "                torch.save(model.state_dict(), save_path_model)\n",
    "                min_accuracy = val_accuracy\n",
    "            \n",
    "    optim_scheduler.step()\n",
    "\n",
    "    train_logger_2.save(train_log_file)\n",
    "    val_logger_2.save(val_log_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDtEzHAvZD5wg/3/fK+fmU",
   "name": "train_pipeline_MS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "056980d18ea54cb887e09ee2d1cf08ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38ef672389194c63af556682bcdfa612": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "43d821a2ad0e484484d13d924a435920": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48dc2d6bc04b4922bdfda5543c32551a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "953b1cb988ef4cd98e71dc38111c710f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48dc2d6bc04b4922bdfda5543c32551a",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38ef672389194c63af556682bcdfa612",
      "value": 87306240
     }
    },
    "9c057e399c704c43a03beb529d12ae2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_953b1cb988ef4cd98e71dc38111c710f",
       "IPY_MODEL_a08bc17b8b4543bf940995d154777641"
      ],
      "layout": "IPY_MODEL_b562fe7ff1b644ce8a68d6d9c39ae859"
     }
    },
    "a08bc17b8b4543bf940995d154777641": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_056980d18ea54cb887e09ee2d1cf08ab",
      "placeholder": "​",
      "style": "IPY_MODEL_43d821a2ad0e484484d13d924a435920",
      "value": " 83.3M/83.3M [00:12&lt;00:00, 7.12MB/s]"
     }
    },
    "b562fe7ff1b644ce8a68d6d9c39ae859": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
